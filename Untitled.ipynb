{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf44b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mask files missing in CSV: 0\n",
      "Number of CSV entries missing in masks: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 932ms/step - accuracy: 0.5978 - loss: 1.9296 - precision_1: 0.5978 - recall_1: 0.5978 - val_accuracy: 0.5439 - val_loss: 0.6858 - val_precision_1: 0.5439 - val_recall_1: 0.5439\n",
      "Epoch 2/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step - accuracy: 0.6668 - loss: 0.6582 - precision_1: 0.6668 - recall_1: 0.6668 - val_accuracy: 0.6140 - val_loss: 0.7080 - val_precision_1: 0.6140 - val_recall_1: 0.6140\n",
      "Epoch 3/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 527ms/step - accuracy: 0.6137 - loss: 0.6733 - precision_1: 0.6137 - recall_1: 0.6137 - val_accuracy: 0.6754 - val_loss: 0.5980 - val_precision_1: 0.6754 - val_recall_1: 0.6754\n",
      "Epoch 4/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 488ms/step - accuracy: 0.7295 - loss: 0.5626 - precision_1: 0.7295 - recall_1: 0.7295 - val_accuracy: 0.6404 - val_loss: 0.6372 - val_precision_1: 0.6404 - val_recall_1: 0.6404\n",
      "Epoch 5/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 533ms/step - accuracy: 0.7400 - loss: 0.5357 - precision_1: 0.7400 - recall_1: 0.7400 - val_accuracy: 0.6930 - val_loss: 0.5996 - val_precision_1: 0.6930 - val_recall_1: 0.6930\n",
      "Epoch 6/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - accuracy: 0.7680 - loss: 0.5001 - precision_1: 0.7680 - recall_1: 0.7680 - val_accuracy: 0.7456 - val_loss: 0.5359 - val_precision_1: 0.7456 - val_recall_1: 0.7456\n",
      "Epoch 7/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 519ms/step - accuracy: 0.8339 - loss: 0.4061 - precision_1: 0.8339 - recall_1: 0.8339 - val_accuracy: 0.7456 - val_loss: 0.5234 - val_precision_1: 0.7456 - val_recall_1: 0.7456\n",
      "Epoch 8/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 481ms/step - accuracy: 0.8721 - loss: 0.3398 - precision_1: 0.8721 - recall_1: 0.8721 - val_accuracy: 0.7368 - val_loss: 0.6028 - val_precision_1: 0.7368 - val_recall_1: 0.7368\n",
      "Epoch 9/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 440ms/step - accuracy: 0.8640 - loss: 0.2975 - precision_1: 0.8640 - recall_1: 0.8640 - val_accuracy: 0.7368 - val_loss: 0.5906 - val_precision_1: 0.7368 - val_recall_1: 0.7368\n",
      "Epoch 10/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 442ms/step - accuracy: 0.9129 - loss: 0.2078 - precision_1: 0.9129 - recall_1: 0.9129 - val_accuracy: 0.7193 - val_loss: 0.7452 - val_precision_1: 0.7193 - val_recall_1: 0.7193\n",
      "Epoch 11/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 442ms/step - accuracy: 0.9576 - loss: 0.1295 - precision_1: 0.9576 - recall_1: 0.9576 - val_accuracy: 0.6842 - val_loss: 0.8387 - val_precision_1: 0.6842 - val_recall_1: 0.6842\n",
      "Epoch 12/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 445ms/step - accuracy: 0.9605 - loss: 0.1181 - precision_1: 0.9605 - recall_1: 0.9605 - val_accuracy: 0.7193 - val_loss: 0.8942 - val_precision_1: 0.7193 - val_recall_1: 0.7193\n",
      "Epoch 13/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 500ms/step - accuracy: 0.9876 - loss: 0.0811 - precision_1: 0.9876 - recall_1: 0.9876 - val_accuracy: 0.7368 - val_loss: 0.9654 - val_precision_1: 0.7368 - val_recall_1: 0.7368\n",
      "Epoch 14/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 476ms/step - accuracy: 0.9906 - loss: 0.0347 - precision_1: 0.9906 - recall_1: 0.9906 - val_accuracy: 0.7105 - val_loss: 1.0638 - val_precision_1: 0.7105 - val_recall_1: 0.7105\n",
      "Epoch 15/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0198 - precision_1: 1.0000 - recall_1: 1.0000 - val_accuracy: 0.7544 - val_loss: 1.1012 - val_precision_1: 0.7544 - val_recall_1: 0.7544\n",
      "Epoch 16/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 442ms/step - accuracy: 1.0000 - loss: 0.0089 - precision_1: 1.0000 - recall_1: 1.0000 - val_accuracy: 0.7281 - val_loss: 1.3400 - val_precision_1: 0.7281 - val_recall_1: 0.7281\n",
      "Epoch 17/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0051 - precision_1: 1.0000 - recall_1: 1.0000 - val_accuracy: 0.7281 - val_loss: 1.3058 - val_precision_1: 0.7281 - val_recall_1: 0.7281\n",
      "Epoch 18/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0017 - precision_1: 1.0000 - recall_1: 1.0000 - val_accuracy: 0.7368 - val_loss: 1.4203 - val_precision_1: 0.7368 - val_recall_1: 0.7368\n",
      "Epoch 19/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 517ms/step - accuracy: 1.0000 - loss: 0.0012 - precision_1: 1.0000 - recall_1: 1.0000 - val_accuracy: 0.7281 - val_loss: 1.4434 - val_precision_1: 0.7281 - val_recall_1: 0.7281\n",
      "Epoch 20/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 8.9409e-04 - precision_1: 1.0000 - recall_1: 1.0000 - val_accuracy: 0.7281 - val_loss: 1.4804 - val_precision_1: 0.7281 - val_recall_1: 0.7281\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7246 - loss: 1.5997 - precision_1: 0.7246 - recall_1: 0.7246\n",
      "Test Accuracy: 0.7281\n",
      "Test Precision: 0.7281\n",
      "Test Recall: 0.7281\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Paths to the directories and CSV file\n",
    "segmented_masks_path = \"D:\\\\CANCER-DETECTION\\\\masks\"\n",
    "csv_file_path = \"D:\\\\CANCER-DETECTION\\\\output.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "patient_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Function to load segmented mask images\n",
    "def load_segmented_masks(segmented_masks_path, target_size=(256, 256)):\n",
    "    masks = []\n",
    "    filenames = []\n",
    "\n",
    "    mask_files = [f for f in os.listdir(segmented_masks_path) if f.endswith('_mask.png')]\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask_path = os.path.join(segmented_masks_path, mask_file)\n",
    "        mask = load_img(mask_path, color_mode='grayscale', target_size=target_size)\n",
    "        mask = img_to_array(mask)\n",
    "        \n",
    "        # Normalize\n",
    "        mask = mask / 255.0\n",
    "        \n",
    "        masks.append(mask)\n",
    "        filenames.append(mask_file.replace('_mask.png', '.txt'))\n",
    "\n",
    "    return np.array(masks), filenames\n",
    "\n",
    "masks, mask_filenames = load_segmented_masks(segmented_masks_path)\n",
    "\n",
    "# Create a DataFrame for the mask filenames\n",
    "mask_df = pd.DataFrame(mask_filenames, columns=['File Name'])\n",
    "\n",
    "# Ensure the 'filename' column in patient_data matches the format of mask_filenames\n",
    "patient_data['File Name'] = patient_data['File Name'].apply(lambda x: x.replace('.png', ''))\n",
    "\n",
    "# Debugging: Find mask filenames without corresponding entries in the CSV\n",
    "mask_filenames_set = set(mask_filenames)\n",
    "csv_filenames_set = set(patient_data['File Name'])\n",
    "\n",
    "missing_in_csv = mask_filenames_set - csv_filenames_set\n",
    "missing_in_masks = csv_filenames_set - mask_filenames_set\n",
    "\n",
    "print(f\"Number of mask files missing in CSV: {len(missing_in_csv)}\")\n",
    "print(f\"Number of CSV entries missing in masks: {len(missing_in_masks)}\")\n",
    "\n",
    "if len(missing_in_csv) > 0:\n",
    "    print(\"Mask files missing in CSV:\")\n",
    "    print(missing_in_csv)\n",
    "\n",
    "if len(missing_in_masks) > 0:\n",
    "    print(\"CSV entries missing in masks:\")\n",
    "    print(missing_in_masks)\n",
    "\n",
    "# Remove inconsistencies\n",
    "mask_df = mask_df[mask_df['File Name'].isin(csv_filenames_set)]\n",
    "patient_data = patient_data[patient_data['File Name'].isin(mask_filenames_set)]\n",
    "\n",
    "# Merge the mask DataFrame with the patient data CSV on the file name\n",
    "merged_data = pd.merge(mask_df, patient_data, on='File Name', how='inner')\n",
    "\n",
    "# Encode the labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = merged_data['Disease']\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Check consistency between masks and labels\n",
    "assert len(masks) == len(labels_encoded), \"Mismatch in the number of masks and labels\"\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(masks, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Define a simple CNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 1)  # Adjust this according to your input size\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = build_cnn(input_shape, num_classes)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "test_loss = results[0]\n",
    "test_accuracy = results[1]\n",
    "test_precision = results[2]\n",
    "test_recall = results[3]\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Precision: {test_precision:.4f}')\n",
    "print(f'Test Recall: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01cb5e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4804033041000366,\n",
       " 0.7280701994895935,\n",
       " 0.7280701994895935,\n",
       " 0.7280701994895935]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bf040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
